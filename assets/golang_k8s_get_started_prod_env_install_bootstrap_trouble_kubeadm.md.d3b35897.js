import{_ as s,o as e,c as a,Q as o}from"./chunks/framework.01af844e.js";const E=JSON.parse('{"title":"Troubleshooting kubeadm","description":"","frontmatter":{},"headers":[],"relativePath":"golang/k8s/get_started/prod_env/install/bootstrap/trouble_kubeadm.md","filePath":"golang/k8s/get_started/prod_env/install/bootstrap/trouble_kubeadm.md","lastUpdated":1693758126000}'),n={name:"golang/k8s/get_started/prod_env/install/bootstrap/trouble_kubeadm.md"},l=o(`<h1 id="troubleshooting-kubeadm" tabindex="-1">Troubleshooting kubeadm <a class="header-anchor" href="#troubleshooting-kubeadm" aria-label="Permalink to &quot;Troubleshooting kubeadm&quot;">​</a></h1><p>As with any program, you might run into an error installing or running kubeadm. This page lists some common failure scenarios and have provided steps that can help you understand and fix the problem.</p><p>If your problem is not listed below, please follow the following steps:</p><ul><li><p>If you think your problem is a bug with kubeadm:</p><ul><li>Go to <a href="https://github.com/kubernetes/kubeadm/issues" target="_blank" rel="noreferrer">github.com/kubernetes/kubeadm</a> and search for existing issues.</li><li>If no issue exists, please <a href="https://github.com/kubernetes/kubeadm/issues/new" target="_blank" rel="noreferrer">open one</a> and follow the issue template.</li></ul></li><li><p>If you are unsure about how kubeadm works, you can ask on <a href="https://slack.k8s.io/" target="_blank" rel="noreferrer">Slack</a> in <code>#kubeadm</code>, or open a question on <a href="https://stackoverflow.com/questions/tagged/kubernetes" target="_blank" rel="noreferrer">StackOverflow</a>. Please include relevant tags like <code>#kubernetes</code> and <code>#kubeadm</code> so folks can help you.</p></li></ul><h2 id="not-possible-to-join-a-v1-18-node-to-a-v1-17-cluster-due-to-missing-rbac" tabindex="-1">Not possible to join a v1.18 Node to a v1.17 cluster due to missing RBAC <a class="header-anchor" href="#not-possible-to-join-a-v1-18-node-to-a-v1-17-cluster-due-to-missing-rbac" aria-label="Permalink to &quot;Not possible to join a v1.18 Node to a v1.17 cluster due to missing RBAC&quot;">​</a></h2><p>In v1.18 kubeadm added prevention for joining a Node in the cluster if a Node with the same name already exists. This required adding RBAC for the bootstrap-token user to be able to GET a Node object.</p><p>However this causes an issue where <code>kubeadm join</code> from v1.18 cannot join a cluster created by kubeadm v1.17.</p><p>To workaround the issue you have two options:</p><p>Execute <code>kubeadm init phase bootstrap-token</code> on a control-plane node using kubeadm v1.18. Note that this enables the rest of the bootstrap-token permissions as well.</p><p>or</p><p>Apply the following RBAC manually using <code>kubectl apply -f ...</code>:</p><div class="language-yaml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">yaml</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#85E89D;">apiVersion</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">rbac.authorization.k8s.io/v1</span></span>
<span class="line"><span style="color:#85E89D;">kind</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">ClusterRole</span></span>
<span class="line"><span style="color:#85E89D;">metadata</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#85E89D;">name</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">kubeadm:get-nodes</span></span>
<span class="line"><span style="color:#85E89D;">rules</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">  - </span><span style="color:#85E89D;">apiGroups</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">      - </span><span style="color:#9ECBFF;">&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#85E89D;">resources</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">      - </span><span style="color:#9ECBFF;">nodes</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#85E89D;">verbs</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">      - </span><span style="color:#9ECBFF;">get</span></span>
<span class="line"><span style="color:#B392F0;">---</span></span>
<span class="line"><span style="color:#85E89D;">apiVersion</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">rbac.authorization.k8s.io/v1</span></span>
<span class="line"><span style="color:#85E89D;">kind</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">ClusterRoleBinding</span></span>
<span class="line"><span style="color:#85E89D;">metadata</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#85E89D;">name</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">kubeadm:get-nodes</span></span>
<span class="line"><span style="color:#85E89D;">roleRef</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#85E89D;">apiGroup</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">rbac.authorization.k8s.io</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#85E89D;">kind</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">ClusterRole</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#85E89D;">name</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">kubeadm:get-nodes</span></span>
<span class="line"><span style="color:#85E89D;">subjects</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">  - </span><span style="color:#85E89D;">apiGroup</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">rbac.authorization.k8s.io</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#85E89D;">kind</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">Group</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#85E89D;">name</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">system:bootstrappers:kubeadm:default-node-token</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#22863A;">apiVersion</span><span style="color:#24292E;">: </span><span style="color:#032F62;">rbac.authorization.k8s.io/v1</span></span>
<span class="line"><span style="color:#22863A;">kind</span><span style="color:#24292E;">: </span><span style="color:#032F62;">ClusterRole</span></span>
<span class="line"><span style="color:#22863A;">metadata</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">kubeadm:get-nodes</span></span>
<span class="line"><span style="color:#22863A;">rules</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">apiGroups</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">      - </span><span style="color:#032F62;">&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">resources</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">      - </span><span style="color:#032F62;">nodes</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">verbs</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">      - </span><span style="color:#032F62;">get</span></span>
<span class="line"><span style="color:#6F42C1;">---</span></span>
<span class="line"><span style="color:#22863A;">apiVersion</span><span style="color:#24292E;">: </span><span style="color:#032F62;">rbac.authorization.k8s.io/v1</span></span>
<span class="line"><span style="color:#22863A;">kind</span><span style="color:#24292E;">: </span><span style="color:#032F62;">ClusterRoleBinding</span></span>
<span class="line"><span style="color:#22863A;">metadata</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">kubeadm:get-nodes</span></span>
<span class="line"><span style="color:#22863A;">roleRef</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#22863A;">apiGroup</span><span style="color:#24292E;">: </span><span style="color:#032F62;">rbac.authorization.k8s.io</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#22863A;">kind</span><span style="color:#24292E;">: </span><span style="color:#032F62;">ClusterRole</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">kubeadm:get-nodes</span></span>
<span class="line"><span style="color:#22863A;">subjects</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">apiGroup</span><span style="color:#24292E;">: </span><span style="color:#032F62;">rbac.authorization.k8s.io</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">kind</span><span style="color:#24292E;">: </span><span style="color:#032F62;">Group</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">system:bootstrappers:kubeadm:default-node-token</span></span></code></pre></div><h2 id="ebtables-or-some-similar-executable-not-found-during-installation" tabindex="-1">ebtables or some similar executable not found during installation <a class="header-anchor" href="#ebtables-or-some-similar-executable-not-found-during-installation" aria-label="Permalink to &quot;ebtables or some similar executable not found during installation&quot;">​</a></h2><p>If you see the following warnings while running <code>kubeadm init</code></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">[preflight] WARNING: ebtables not found in system path</span></span>
<span class="line"><span style="color:#e1e4e8;">[preflight] WARNING: ethtool not found in system path</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">[preflight] WARNING: ebtables not found in system path</span></span>
<span class="line"><span style="color:#24292e;">[preflight] WARNING: ethtool not found in system path</span></span></code></pre></div><p>Then you may be missing <code>ebtables</code>, <code>ethtool</code> or a similar executable on your node. You can install them with the following commands:</p><ul><li>For Ubuntu/Debian users, run <code>apt install ebtables ethtool</code>.</li><li>For CentOS/Fedora users, run <code>yum install ebtables ethtool</code>.</li></ul><h2 id="kubeadm-blocks-waiting-for-control-plane-during-installation" tabindex="-1">kubeadm blocks waiting for control plane during installation <a class="header-anchor" href="#kubeadm-blocks-waiting-for-control-plane-during-installation" aria-label="Permalink to &quot;kubeadm blocks waiting for control plane during installation&quot;">​</a></h2><p>If you notice that <code>kubeadm init</code> hangs after printing out the following line:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">[apiclient] Created API client, waiting for the control plane to become ready</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">[apiclient] Created API client, waiting for the control plane to become ready</span></span></code></pre></div><p>This may be caused by a number of problems. The most common are:</p><ul><li>network connection problems. Check that your machine has full network connectivity before continuing.</li><li>the cgroup driver of the container runtime differs from that of the kubelet. To understand how to configure it properly see <a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/" target="_blank" rel="noreferrer">Configuring a cgroup driver</a>.</li><li>control plane containers are crashlooping or hanging. You can check this by running <code>docker ps</code> and investigating each container by running <code>docker logs</code>. For other container runtime see <a href="https://kubernetes.io/docs/tasks/debug/debug-cluster/crictl/" target="_blank" rel="noreferrer">Debugging Kubernetes nodes with crictl</a>.</li></ul><h2 id="kubeadm-blocks-when-removing-managed-containers" tabindex="-1">kubeadm blocks when removing managed containers <a class="header-anchor" href="#kubeadm-blocks-when-removing-managed-containers" aria-label="Permalink to &quot;kubeadm blocks when removing managed containers&quot;">​</a></h2><p>The following could happen if the container runtime halts and does not remove any Kubernetes-managed containers:</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">sudo</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">kubeadm</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">reset</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">sudo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">kubeadm</span><span style="color:#24292E;"> </span><span style="color:#032F62;">reset</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">[preflight] Running pre-flight checks</span></span>
<span class="line"><span style="color:#e1e4e8;">[reset] Stopping the kubelet service</span></span>
<span class="line"><span style="color:#e1e4e8;">[reset] Unmounting mounted directories in &quot;/var/lib/kubelet&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;">[reset] Removing kubernetes-managed containers</span></span>
<span class="line"><span style="color:#e1e4e8;">(block)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">[preflight] Running pre-flight checks</span></span>
<span class="line"><span style="color:#24292e;">[reset] Stopping the kubelet service</span></span>
<span class="line"><span style="color:#24292e;">[reset] Unmounting mounted directories in &quot;/var/lib/kubelet&quot;</span></span>
<span class="line"><span style="color:#24292e;">[reset] Removing kubernetes-managed containers</span></span>
<span class="line"><span style="color:#24292e;">(block)</span></span></code></pre></div><p>A possible solution is to restart the container runtime and then re-run <code>kubeadm reset</code>. You can also use <code>crictl</code> to debug the state of the container runtime. See <a href="https://kubernetes.io/docs/tasks/debug/debug-cluster/crictl/" target="_blank" rel="noreferrer">Debugging Kubernetes nodes with crictl</a>.</p><h2 id="pods-in-runcontainererror-crashloopbackoff-or-error-state" tabindex="-1">Pods in RunContainerError, CrashLoopBackOff or Error state <a class="header-anchor" href="#pods-in-runcontainererror-crashloopbackoff-or-error-state" aria-label="Permalink to &quot;Pods in RunContainerError, CrashLoopBackOff or Error state&quot;">​</a></h2><p>Right after <code>kubeadm init</code> there should not be any pods in these states.</p><ul><li>If there are pods in one of these states right after <code>kubeadm init</code>, please open an issue in the kubeadm repo. <code>coredns</code> (or <code>kube-dns</code>) should be in the <code>Pending</code> state until you have deployed the network add-on.</li><li>If you see Pods in the <code>RunContainerError</code>, <code>CrashLoopBackOff</code> or <code>Error</code> state after deploying the network add-on and nothing happens to <code>coredns</code> (or <code>kube-dns</code>), it&#39;s very likely that the Pod Network add-on that you installed is somehow broken. You might have to grant it more RBAC privileges or use a newer version. Please file an issue in the Pod Network providers&#39; issue tracker and get the issue triaged there.</li></ul><h2 id="coredns-is-stuck-in-the-pending-state" tabindex="-1">coredns is stuck in the Pending state <a class="header-anchor" href="#coredns-is-stuck-in-the-pending-state" aria-label="Permalink to &quot;coredns is stuck in the Pending state&quot;">​</a></h2><p>This is expected and part of the design. kubeadm is network provider-agnostic, so the admin should <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/" target="_blank" rel="noreferrer">install the pod network add-on</a> of choice. You have to install a Pod Network before CoreDNS may be deployed fully. Hence the <code>Pending</code> state before the network is set up.</p><h2 id="hostport-services-do-not-work" tabindex="-1">HostPort services do not work <a class="header-anchor" href="#hostport-services-do-not-work" aria-label="Permalink to &quot;HostPort services do not work&quot;">​</a></h2><p>The <code>HostPort</code> and <code>HostIP</code> functionality is available depending on your Pod Network provider. Please contact the author of the Pod Network add-on to find out whether <code>HostPort</code> and <code>HostIP</code> functionality are available.</p><p>Calico, Canal, and Flannel CNI providers are verified to support HostPort.</p><p>For more information, see the <a href="https://github.com/containernetworking/plugins/blob/master/plugins/meta/portmap/README.md" target="_blank" rel="noreferrer">CNI portmap documentation</a>.</p><p>If your network provider does not support the portmap CNI plugin, you may need to use the <a href="https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport" target="_blank" rel="noreferrer">NodePort feature of services</a> or use <code>HostNetwork=true</code>.</p><h2 id="pods-are-not-accessible-via-their-service-ip" tabindex="-1">Pods are not accessible via their Service IP <a class="header-anchor" href="#pods-are-not-accessible-via-their-service-ip" aria-label="Permalink to &quot;Pods are not accessible via their Service IP&quot;">​</a></h2><ul><li><p>Many network add-ons do not yet enable <a href="https://kubernetes.io/docs/tasks/debug/debug-application/debug-service/#a-pod-fails-to-reach-itself-via-the-service-ip" target="_blank" rel="noreferrer">hairpin mode</a> which allows pods to access themselves via their Service IP. This is an issue related to <a href="https://github.com/containernetworking/cni/issues/476" target="_blank" rel="noreferrer">CNI</a>. Please contact the network add-on provider to get the latest status of their support for hairpin mode.</p></li><li><p>If you are using VirtualBox (directly or via Vagrant), you will need to ensure that <code>hostname -i</code> returns a routable IP address. By default the first interface is connected to a non-routable host-only network. A work around is to modify <code>/etc/hosts</code>, see this <a href="https://github.com/errordeveloper/k8s-playground/blob/22dd39dfc06111235620e6c4404a96ae146f26fd/Vagrantfile#L11" target="_blank" rel="noreferrer">Vagrantfile</a> for an example.</p></li></ul><h2 id="tls-certificate-errors" tabindex="-1">TLS certificate errors <a class="header-anchor" href="#tls-certificate-errors" aria-label="Permalink to &quot;TLS certificate errors&quot;">​</a></h2><p>The following error indicates a possible certificate mismatch.</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># kubectl get pods</span></span>
<span class="line"><span style="color:#B392F0;">Unable</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">to</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">connect</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">to</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">the</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">server:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">x509:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">certificate</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">signed</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">by</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">unknown</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">authority</span><span style="color:#E1E4E8;"> (possibly </span><span style="color:#9ECBFF;">because</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">of</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;crypto/rsa: verification error&quot;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">while</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">trying</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">to</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">verify</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">candidate</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">authority</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">certificate</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;kubernetes&quot;</span><span style="color:#E1E4E8;">)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># kubectl get pods</span></span>
<span class="line"><span style="color:#6F42C1;">Unable</span><span style="color:#24292E;"> </span><span style="color:#032F62;">to</span><span style="color:#24292E;"> </span><span style="color:#032F62;">connect</span><span style="color:#24292E;"> </span><span style="color:#032F62;">to</span><span style="color:#24292E;"> </span><span style="color:#032F62;">the</span><span style="color:#24292E;"> </span><span style="color:#032F62;">server:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">x509:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">certificate</span><span style="color:#24292E;"> </span><span style="color:#032F62;">signed</span><span style="color:#24292E;"> </span><span style="color:#032F62;">by</span><span style="color:#24292E;"> </span><span style="color:#032F62;">unknown</span><span style="color:#24292E;"> </span><span style="color:#032F62;">authority</span><span style="color:#24292E;"> (possibly </span><span style="color:#032F62;">because</span><span style="color:#24292E;"> </span><span style="color:#032F62;">of</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;crypto/rsa: verification error&quot;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">while</span><span style="color:#24292E;"> </span><span style="color:#032F62;">trying</span><span style="color:#24292E;"> </span><span style="color:#032F62;">to</span><span style="color:#24292E;"> </span><span style="color:#032F62;">verify</span><span style="color:#24292E;"> </span><span style="color:#032F62;">candidate</span><span style="color:#24292E;"> </span><span style="color:#032F62;">authority</span><span style="color:#24292E;"> </span><span style="color:#032F62;">certificate</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;kubernetes&quot;</span><span style="color:#24292E;">)</span></span></code></pre></div><ul><li><p>Verify that the <code>$HOME/.kube/config</code> file contains a valid certificate, and regenerate a certificate if necessary. The certificates in a kubeconfig file are base64 encoded. The <code>base64 --decode</code> command can be used to decode the certificate and <code>openssl x509 -text -noout</code> can be used for viewing the certificate information.</p></li><li><p>Unset the <code>KUBECONFIG</code> environment variable using:</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#79B8FF;">unset</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">KUBECONFIG</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#005CC5;">unset</span><span style="color:#24292E;"> </span><span style="color:#032F62;">KUBECONFIG</span></span></code></pre></div><p>Or set it to the default <code>KUBECONFIG</code> location:</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">export</span><span style="color:#E1E4E8;"> KUBECONFIG</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">/etc/kubernetes/admin.conf</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">export</span><span style="color:#24292E;"> KUBECONFIG</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">/etc/kubernetes/admin.conf</span></span></code></pre></div></li><li><p>Another workaround is to overwrite the existing <code>kubeconfig</code> for the &quot;admin&quot; user:</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">mv</span><span style="color:#E1E4E8;">  $HOME</span><span style="color:#9ECBFF;">/.kube</span><span style="color:#E1E4E8;"> $HOME</span><span style="color:#9ECBFF;">/.kube.bak</span></span>
<span class="line"><span style="color:#B392F0;">mkdir</span><span style="color:#E1E4E8;"> $HOME</span><span style="color:#9ECBFF;">/.kube</span></span>
<span class="line"><span style="color:#B392F0;">sudo</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">cp</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-i</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">/etc/kubernetes/admin.conf</span><span style="color:#E1E4E8;"> $HOME</span><span style="color:#9ECBFF;">/.kube/config</span></span>
<span class="line"><span style="color:#B392F0;">sudo</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">chown</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">$(</span><span style="color:#B392F0;">id</span><span style="color:#9ECBFF;"> </span><span style="color:#79B8FF;">-u</span><span style="color:#9ECBFF;">):$(</span><span style="color:#B392F0;">id</span><span style="color:#9ECBFF;"> </span><span style="color:#79B8FF;">-g</span><span style="color:#9ECBFF;">)</span><span style="color:#E1E4E8;"> $HOME</span><span style="color:#9ECBFF;">/.kube/config</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">mv</span><span style="color:#24292E;">  $HOME</span><span style="color:#032F62;">/.kube</span><span style="color:#24292E;"> $HOME</span><span style="color:#032F62;">/.kube.bak</span></span>
<span class="line"><span style="color:#6F42C1;">mkdir</span><span style="color:#24292E;"> $HOME</span><span style="color:#032F62;">/.kube</span></span>
<span class="line"><span style="color:#6F42C1;">sudo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">cp</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-i</span><span style="color:#24292E;"> </span><span style="color:#032F62;">/etc/kubernetes/admin.conf</span><span style="color:#24292E;"> $HOME</span><span style="color:#032F62;">/.kube/config</span></span>
<span class="line"><span style="color:#6F42C1;">sudo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">chown</span><span style="color:#24292E;"> </span><span style="color:#032F62;">$(</span><span style="color:#6F42C1;">id</span><span style="color:#032F62;"> </span><span style="color:#005CC5;">-u</span><span style="color:#032F62;">):$(</span><span style="color:#6F42C1;">id</span><span style="color:#032F62;"> </span><span style="color:#005CC5;">-g</span><span style="color:#032F62;">)</span><span style="color:#24292E;"> $HOME</span><span style="color:#032F62;">/.kube/config</span></span></code></pre></div></li></ul><h2 id="kubelet-client-certificate-rotation-fails" tabindex="-1">Kubelet client certificate rotation fails <a class="header-anchor" href="#kubelet-client-certificate-rotation-fails" aria-label="Permalink to &quot;Kubelet client certificate rotation fails&quot;">​</a></h2><p>By default, kubeadm configures a kubelet with automatic rotation of client certificates by using the <code>/var/lib/kubelet/pki/kubelet-client-current.pem</code> symlink specified in <code>/etc/kubernetes/kubelet.conf</code>. If this rotation process fails you might see errors such as <code>x509: certificate has expired or is not yet valid</code> in kube-apiserver logs. To fix the issue you must follow these steps:</p><ol><li><p>Backup and delete <code>/etc/kubernetes/kubelet.conf</code> and <code>/var/lib/kubelet/pki/kubelet-client*</code> from the failed node.</p></li><li><p>From a working control plane node in the cluster that has <code>/etc/kubernetes/pki/ca.key</code> execute <code>kubeadm kubeconfig user --org system:nodes --client-name system:node:$NODE &gt; kubelet.conf</code>. <code>$NODE</code> must be set to the name of the existing failed node in the cluster. Modify the resulted <code>kubelet.conf</code> manually to adjust the cluster name and server endpoint, or pass <code>kubeconfig user --config</code> (it accepts <code>InitConfiguration</code>). If your cluster does not have the <code>ca.key</code> you must sign the embedded certificates in the <code>kubelet.conf</code> externally.</p></li><li><p>Copy this resulted <code>kubelet.conf</code> to <code>/etc/kubernetes/kubelet.conf</code> on the failed node.</p></li><li><p>Restart the kubelet (<code>systemctl restart kubelet</code>) on the failed node and wait for <code>/var/lib/kubelet/pki/kubelet-client-current.pem</code> to be recreated.</p></li><li><p>Manually edit the <code>kubelet.conf</code> to point to the rotated kubelet client certificates, by replacing <code>client-certificate-data</code> and <code>client-key-data</code> with:</p></li></ol><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">client-certificate: /var/lib/kubelet/pki/kubelet-client-current.pem</span></span>
<span class="line"><span style="color:#e1e4e8;">client-key: /var/lib/kubelet/pki/kubelet-client-current.pem</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">client-certificate: /var/lib/kubelet/pki/kubelet-client-current.pem</span></span>
<span class="line"><span style="color:#24292e;">client-key: /var/lib/kubelet/pki/kubelet-client-current.pem</span></span></code></pre></div><ol start="6"><li><p>Restart the kubelet.</p></li><li><p>Make sure the node becomes Ready.</p></li></ol><h2 id="default-nic-when-using-flannel-as-the-pod-network-in-vagrant" tabindex="-1">Default NIC When using flannel as the pod network in Vagrant <a class="header-anchor" href="#default-nic-when-using-flannel-as-the-pod-network-in-vagrant" aria-label="Permalink to &quot;Default NIC When using flannel as the pod network in Vagrant&quot;">​</a></h2><p>The following error might indicate that something was wrong in the pod network:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">Error from server (NotFound): the server could not find the requested resource</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">Error from server (NotFound): the server could not find the requested resource</span></span></code></pre></div><ul><li><p>If you&#39;re using flannel as the pod network inside Vagrant, then you will have to specify the default interface name for flannel.</p><p>Vagrant typically assigns two interfaces to all VMs. The first, for which all hosts are assigned the IP address <code>10.0.2.15</code>, is for external traffic that gets NATed.</p><p>This may lead to problems with flannel, which defaults to the first interface on a host. This leads to all hosts thinking they have the same public IP address. To prevent this, pass the <code>--iface eth1</code> flag to flannel so that the second interface is chosen.</p></li></ul><h2 id="non-public-ip-used-for-containers" tabindex="-1">Non-public IP used for containers <a class="header-anchor" href="#non-public-ip-used-for-containers" aria-label="Permalink to &quot;Non-public IP used for containers&quot;">​</a></h2><p>In some situations <code>kubectl logs</code> and <code>kubectl run</code> commands may return with the following errors in an otherwise functional cluster:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">Error from server: Get https://10.19.0.41:10250/containerLogs/default/mysql-ddc65b868-glc5m/mysql: dial tcp 10.19.0.41:10250: getsockopt: no route to host</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">Error from server: Get https://10.19.0.41:10250/containerLogs/default/mysql-ddc65b868-glc5m/mysql: dial tcp 10.19.0.41:10250: getsockopt: no route to host</span></span></code></pre></div><ul><li><p>This may be due to Kubernetes using an IP that can not communicate with other IPs on the seemingly same subnet, possibly by policy of the machine provider.</p></li><li><p>DigitalOcean assigns a public IP to <code>eth0</code> as well as a private one to be used internally as anchor for their floating IP feature, yet <code>kubelet</code> will pick the latter as the node&#39;s <code>InternalIP</code> instead of the public one.</p><p>Use <code>ip addr show</code> to check for this scenario instead of <code>ifconfig</code> because <code>ifconfig</code> will not display the offending alias IP address. Alternatively an API endpoint specific to DigitalOcean allows to query for the anchor IP from the droplet:</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">curl</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">http://169.254.169.254/metadata/v1/interfaces/public/0/anchor_ipv4/address</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">curl</span><span style="color:#24292E;"> </span><span style="color:#032F62;">http://169.254.169.254/metadata/v1/interfaces/public/0/anchor_ipv4/address</span></span></code></pre></div><p>The workaround is to tell <code>kubelet</code> which IP to use using <code>--node-ip</code>. When using DigitalOcean, it can be the public one (assigned to <code>eth0</code>) or the private one (assigned to <code>eth1</code>) should you want to use the optional private network. The <code>kubeletExtraArgs</code> section of the kubeadm <a href="https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/#kubeadm-k8s-io-v1beta3-NodeRegistrationOptions" target="_blank" rel="noreferrer">NodeRegistrationOptions structure</a> can be used for this.</p><p>Then restart <code>kubelet</code>:</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">systemctl</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">daemon-reload</span></span>
<span class="line"><span style="color:#B392F0;">systemctl</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">restart</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">kubelet</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">systemctl</span><span style="color:#24292E;"> </span><span style="color:#032F62;">daemon-reload</span></span>
<span class="line"><span style="color:#6F42C1;">systemctl</span><span style="color:#24292E;"> </span><span style="color:#032F62;">restart</span><span style="color:#24292E;"> </span><span style="color:#032F62;">kubelet</span></span></code></pre></div></li></ul><h2 id="coredns-pods-have-crashloopbackoff-or-error-state" tabindex="-1">coredns pods have CrashLoopBackOff or Error state <a class="header-anchor" href="#coredns-pods-have-crashloopbackoff-or-error-state" aria-label="Permalink to &quot;coredns pods have CrashLoopBackOff or Error state&quot;">​</a></h2><p>If you have nodes that are running SELinux with an older version of Docker you might experience a scenario where the <code>coredns</code> pods are not starting. To solve that you can try one of the following options:</p><ul><li><p>Upgrade to a <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#docker" target="_blank" rel="noreferrer">newer version of Docker</a>.</p></li><li><p><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/security-enhanced_linux/sect-security-enhanced_linux-enabling_and_disabling_selinux-disabling_selinux" target="_blank" rel="noreferrer">Disable SELinux</a>.</p></li><li><p>Modify the <code>coredns</code> deployment to set <code>allowPrivilegeEscalation</code> to <code>true</code>:</p></li></ul><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">kubectl</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-n</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">kube-system</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">get</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">deployment</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">coredns</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-o</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">yaml</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">\\</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#B392F0;">sed</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;s/allowPrivilegeEscalation: false/allowPrivilegeEscalation: true/g&#39;</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">\\</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#B392F0;">kubectl</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">apply</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-f</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">-</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">kubectl</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-n</span><span style="color:#24292E;"> </span><span style="color:#032F62;">kube-system</span><span style="color:#24292E;"> </span><span style="color:#032F62;">get</span><span style="color:#24292E;"> </span><span style="color:#032F62;">deployment</span><span style="color:#24292E;"> </span><span style="color:#032F62;">coredns</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-o</span><span style="color:#24292E;"> </span><span style="color:#032F62;">yaml</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">|</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#6F42C1;">sed</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;s/allowPrivilegeEscalation: false/allowPrivilegeEscalation: true/g&#39;</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">|</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#6F42C1;">kubectl</span><span style="color:#24292E;"> </span><span style="color:#032F62;">apply</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-f</span><span style="color:#24292E;"> </span><span style="color:#032F62;">-</span></span></code></pre></div><p>Another cause for CoreDNS to have <code>CrashLoopBackOff</code> is when a CoreDNS Pod deployed in Kubernetes detects a loop. <a href="https://github.com/coredns/coredns/tree/master/plugin/loop#troubleshooting-loops-in-kubernetes-clusters" target="_blank" rel="noreferrer">A number of workarounds</a> are available to avoid Kubernetes trying to restart the CoreDNS Pod every time CoreDNS detects the loop and exits.</p><div class="warning custom-block"><p class="custom-block-title">Warning:</p><p>Disabling SELinux or setting <code>allowPrivilegeEscalation</code> to <code>true</code> can compromise the security of your cluster.</p></div><h2 id="etcd-pods-restart-continually" tabindex="-1">etcd pods restart continually <a class="header-anchor" href="#etcd-pods-restart-continually" aria-label="Permalink to &quot;etcd pods restart continually&quot;">​</a></h2><p>If you encounter the following error:</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">rpc</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">error:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">code</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">desc</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">oci</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">runtime</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">error:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">exec</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">failed:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">container_linux.go:247:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">starting</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">container</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">process</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">caused</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;process_linux.go:110: decoding init error from pipe caused </span><span style="color:#79B8FF;">\\&quot;</span><span style="color:#9ECBFF;">read parent: connection reset by peer</span><span style="color:#79B8FF;">\\&quot;</span><span style="color:#9ECBFF;">&quot;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">rpc</span><span style="color:#24292E;"> </span><span style="color:#032F62;">error:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">code</span><span style="color:#24292E;"> </span><span style="color:#032F62;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#24292E;"> </span><span style="color:#032F62;">desc</span><span style="color:#24292E;"> </span><span style="color:#032F62;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">oci</span><span style="color:#24292E;"> </span><span style="color:#032F62;">runtime</span><span style="color:#24292E;"> </span><span style="color:#032F62;">error:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">exec</span><span style="color:#24292E;"> </span><span style="color:#032F62;">failed:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">container_linux.go:247:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">starting</span><span style="color:#24292E;"> </span><span style="color:#032F62;">container</span><span style="color:#24292E;"> </span><span style="color:#032F62;">process</span><span style="color:#24292E;"> </span><span style="color:#032F62;">caused</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;process_linux.go:110: decoding init error from pipe caused </span><span style="color:#005CC5;">\\&quot;</span><span style="color:#032F62;">read parent: connection reset by peer</span><span style="color:#005CC5;">\\&quot;</span><span style="color:#032F62;">&quot;</span></span></code></pre></div><p>this issue appears if you run CentOS 7 with Docker 1.13.1.84. This version of Docker can prevent the kubelet from executing into the etcd container.</p><p>To work around the issue, choose one of these options:</p><ul><li><p>Roll back to an earlier version of Docker, such as 1.13.1-75</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">yum</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">downgrade</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">docker-1.13.1-75.git8633870.el7.centos.x86_64</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">docker-client-1.13.1-75.git8633870.el7.centos.x86_64</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">docker-common-1.13.1-75.git8633870.el7.centos.x86_64</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">yum</span><span style="color:#24292E;"> </span><span style="color:#032F62;">downgrade</span><span style="color:#24292E;"> </span><span style="color:#032F62;">docker-1.13.1-75.git8633870.el7.centos.x86_64</span><span style="color:#24292E;"> </span><span style="color:#032F62;">docker-client-1.13.1-75.git8633870.el7.centos.x86_64</span><span style="color:#24292E;"> </span><span style="color:#032F62;">docker-common-1.13.1-75.git8633870.el7.centos.x86_64</span></span></code></pre></div></li><li><p>Install one of the more recent recommended versions, such as 18.06:</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">sudo</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">yum-config-manager</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">--add-repo</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">https://download.docker.com/linux/centos/docker-ce.repo</span></span>
<span class="line"><span style="color:#B392F0;">yum</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">install</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">docker-ce-18.06.1.ce-3.el7.x86_64</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">sudo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">yum-config-manager</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">--add-repo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">https://download.docker.com/linux/centos/docker-ce.repo</span></span>
<span class="line"><span style="color:#6F42C1;">yum</span><span style="color:#24292E;"> </span><span style="color:#032F62;">install</span><span style="color:#24292E;"> </span><span style="color:#032F62;">docker-ce-18.06.1.ce-3.el7.x86_64</span></span></code></pre></div></li></ul><h2 id="not-possible-to-pass-a-comma-separated-list-of-values-to-arguments-inside-a-component-extra-args-flag" tabindex="-1">Not possible to pass a comma separated list of values to arguments inside a <code>--component-extra-args</code> flag <a class="header-anchor" href="#not-possible-to-pass-a-comma-separated-list-of-values-to-arguments-inside-a-component-extra-args-flag" aria-label="Permalink to &quot;Not possible to pass a comma separated list of values to arguments inside a \`--component-extra-args\` flag&quot;">​</a></h2><p><code>kubeadm init</code> flags such as <code>--component-extra-args</code> allow you to pass custom arguments to a control-plane component like the kube-apiserver. However, this mechanism is limited due to the underlying type used for parsing the values (<code>mapStringString</code>).</p><p>If you decide to pass an argument that supports multiple, comma-separated values such as <code>--apiserver-extra-args &quot;enable-admission-plugins=LimitRanger,NamespaceExists&quot;</code> this flag will fail with flag: <code>malformed pair, expect string=string</code>. This happens because the list of arguments for <code>--apiserver-extra-args</code> expects <code>key=value</code> pairs and in this case <code>NamespacesExists</code> is considered as a key that is missing a value.</p><p>Alternatively, you can try separating the <code>key=value</code> pairs like so: <code>--apiserver-extra-args &quot;enable-admission-plugins=LimitRanger,enable-admission-plugins=NamespaceExists&quot;</code> but this will result in the key <code>enable-admission-plugins</code> only having the value of <code>NamespaceExists</code>.</p><p>A known workaround is to use the kubeadm <a href="https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/" target="_blank" rel="noreferrer">configuration file</a>.</p><h2 id="kube-proxy-scheduled-before-node-is-initialized-by-cloud-controller-manager" tabindex="-1">kube-proxy scheduled before node is initialized by cloud-controller-manager <a class="header-anchor" href="#kube-proxy-scheduled-before-node-is-initialized-by-cloud-controller-manager" aria-label="Permalink to &quot;kube-proxy scheduled before node is initialized by cloud-controller-manager&quot;">​</a></h2><p>In cloud provider scenarios, kube-proxy can end up being scheduled on new worker nodes before the cloud-controller-manager has initialized the node addresses. This causes kube-proxy to fail to pick up the node&#39;s IP address properly and has knock-on effects to the proxy function managing load balancers.</p><p>The following error can be seen in kube-proxy Pods:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">server.go:610] Failed to retrieve node IP: host IP unknown; known addresses: []</span></span>
<span class="line"><span style="color:#e1e4e8;">proxier.go:340] invalid nodeIP, initializing kube-proxy with 127.0.0.1 as nodeIP</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">server.go:610] Failed to retrieve node IP: host IP unknown; known addresses: []</span></span>
<span class="line"><span style="color:#24292e;">proxier.go:340] invalid nodeIP, initializing kube-proxy with 127.0.0.1 as nodeIP</span></span></code></pre></div><p>A known solution is to patch the kube-proxy DaemonSet to allow scheduling it on control-plane nodes regardless of their conditions, keeping it off of other nodes until their initial guarding conditions abate:</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">kubectl</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-n</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">kube-system</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">patch</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">ds</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">kube-proxy</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-p=</span><span style="color:#9ECBFF;">&#39;{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;tolerations&quot;: [ { &quot;key&quot;: &quot;CriticalAddonsOnly&quot;, &quot;operator&quot;: &quot;Exists&quot; }, { &quot;effect&quot;: &quot;NoSchedule&quot;, &quot;key&quot;: &quot;node-role.kubernetes.io/control-plane&quot; } ] } } } }&#39;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">kubectl</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-n</span><span style="color:#24292E;"> </span><span style="color:#032F62;">kube-system</span><span style="color:#24292E;"> </span><span style="color:#032F62;">patch</span><span style="color:#24292E;"> </span><span style="color:#032F62;">ds</span><span style="color:#24292E;"> </span><span style="color:#032F62;">kube-proxy</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-p=</span><span style="color:#032F62;">&#39;{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;tolerations&quot;: [ { &quot;key&quot;: &quot;CriticalAddonsOnly&quot;, &quot;operator&quot;: &quot;Exists&quot; }, { &quot;effect&quot;: &quot;NoSchedule&quot;, &quot;key&quot;: &quot;node-role.kubernetes.io/control-plane&quot; } ] } } } }&#39;</span></span></code></pre></div><p>The tracking issue for this problem is <a href="https://github.com/kubernetes/kubeadm/issues/1027" target="_blank" rel="noreferrer">here</a>.</p><h2 id="usr-is-mounted-read-only-on-nodes" tabindex="-1"><code>/usr</code> is mounted read-only on nodes <a class="header-anchor" href="#usr-is-mounted-read-only-on-nodes" aria-label="Permalink to &quot;\`/usr\` is mounted read-only on nodes&quot;">​</a></h2><p>On Linux distributions such as Fedora CoreOS or Flatcar Container Linux, the directory <code>/usr</code> is mounted as a read-only filesystem. For <a href="https://github.com/kubernetes/community/blob/ab55d85/contributors/devel/sig-storage/flexvolume.md" target="_blank" rel="noreferrer">flex-volume support</a>, Kubernetes components like the kubelet and kube-controller-manager use the default path of <code>/usr/libexec/kubernetes/kubelet-plugins/volume/exec/</code>, yet the flex-volume directory must be writeable for the feature to work. (Note: FlexVolume was deprecated in the Kubernetes v1.23 release)</p><p>To workaround this issue you can configure the flex-volume directory using the kubeadm <a href="https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/" target="_blank" rel="noreferrer">configuration file</a>.</p><p>On the primary control-plane Node (created using <code>kubeadm init</code>) pass the following file using <code>--config</code>:</p><div class="language-yaml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">yaml</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#85E89D;">apiVersion</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">kubeadm.k8s.io/v1beta3</span></span>
<span class="line"><span style="color:#85E89D;">kind</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">InitConfiguration</span></span>
<span class="line"><span style="color:#85E89D;">nodeRegistration</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#85E89D;">kubeletExtraArgs</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#85E89D;">volume-plugin-dir</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">&quot;/opt/libexec/kubernetes/kubelet-plugins/volume/exec/&quot;</span></span>
<span class="line"><span style="color:#B392F0;">---</span></span>
<span class="line"><span style="color:#85E89D;">apiVersion</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">kubeadm.k8s.io/v1beta3</span></span>
<span class="line"><span style="color:#85E89D;">kind</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">ClusterConfiguration</span></span>
<span class="line"><span style="color:#85E89D;">controllerManager</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#85E89D;">extraArgs</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#85E89D;">flex-volume-plugin-dir</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">&quot;/opt/libexec/kubernetes/kubelet-plugins/volume/exec/&quot;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#22863A;">apiVersion</span><span style="color:#24292E;">: </span><span style="color:#032F62;">kubeadm.k8s.io/v1beta3</span></span>
<span class="line"><span style="color:#22863A;">kind</span><span style="color:#24292E;">: </span><span style="color:#032F62;">InitConfiguration</span></span>
<span class="line"><span style="color:#22863A;">nodeRegistration</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#22863A;">kubeletExtraArgs</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">volume-plugin-dir</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;/opt/libexec/kubernetes/kubelet-plugins/volume/exec/&quot;</span></span>
<span class="line"><span style="color:#6F42C1;">---</span></span>
<span class="line"><span style="color:#22863A;">apiVersion</span><span style="color:#24292E;">: </span><span style="color:#032F62;">kubeadm.k8s.io/v1beta3</span></span>
<span class="line"><span style="color:#22863A;">kind</span><span style="color:#24292E;">: </span><span style="color:#032F62;">ClusterConfiguration</span></span>
<span class="line"><span style="color:#22863A;">controllerManager</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#22863A;">extraArgs</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">flex-volume-plugin-dir</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;/opt/libexec/kubernetes/kubelet-plugins/volume/exec/&quot;</span></span></code></pre></div><p>On joining Nodes:</p><div class="language-yaml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">yaml</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#85E89D;">apiVersion</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">kubeadm.k8s.io/v1beta3</span></span>
<span class="line"><span style="color:#85E89D;">kind</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">JoinConfiguration</span></span>
<span class="line"><span style="color:#85E89D;">nodeRegistration</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">  </span><span style="color:#85E89D;">kubeletExtraArgs</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#85E89D;">volume-plugin-dir</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">&quot;/opt/libexec/kubernetes/kubelet-plugins/volume/exec/&quot;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#22863A;">apiVersion</span><span style="color:#24292E;">: </span><span style="color:#032F62;">kubeadm.k8s.io/v1beta3</span></span>
<span class="line"><span style="color:#22863A;">kind</span><span style="color:#24292E;">: </span><span style="color:#032F62;">JoinConfiguration</span></span>
<span class="line"><span style="color:#22863A;">nodeRegistration</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#22863A;">kubeletExtraArgs</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">volume-plugin-dir</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;/opt/libexec/kubernetes/kubelet-plugins/volume/exec/&quot;</span></span></code></pre></div><p>Alternatively, you can modify <code>/etc/fstab</code> to make the <code>/usr</code> mount writeable, but please be advised that this is modifying a design principle of the Linux distribution.</p><h2 id="kubeadm-upgrade-plan-prints-out-context-deadline-exceeded-error-message" tabindex="-1"><code>kubeadm upgrade plan</code> prints out <code>context deadline exceeded</code> error message <a class="header-anchor" href="#kubeadm-upgrade-plan-prints-out-context-deadline-exceeded-error-message" aria-label="Permalink to &quot;\`kubeadm upgrade plan\` prints out \`context deadline exceeded\` error message&quot;">​</a></h2><p>This error message is shown when upgrading a Kubernetes cluster with <code>kubeadm</code> in the case of running an external etcd. This is not a critical bug and happens because older versions of kubeadm perform a version check on the external etcd cluster. You can proceed with <code>kubeadm upgrade apply ....</code></p><p>This issue is fixed as of version 1.19.</p><h2 id="kubeadm-reset-unmounts-var-lib-kubelet" tabindex="-1"><code>kubeadm reset</code> unmounts <code>/var/lib/kubelet</code> <a class="header-anchor" href="#kubeadm-reset-unmounts-var-lib-kubelet" aria-label="Permalink to &quot;\`kubeadm reset\` unmounts \`/var/lib/kubelet\`&quot;">​</a></h2><p>If <code>/var/lib/kubelet</code> is being mounted, performing a <code>kubeadm reset</code> will effectively unmount it.</p><p>To workaround the issue, re-mount the <code>/var/lib/kubelet</code> directory after performing the <code>kubeadm reset</code> operation.</p><p>This is a regression introduced in kubeadm 1.15. The issue is fixed in 1.20.</p><h2 id="cannot-use-the-metrics-server-securely-in-a-kubeadm-cluster" tabindex="-1">Cannot use the metrics-server securely in a kubeadm cluster <a class="header-anchor" href="#cannot-use-the-metrics-server-securely-in-a-kubeadm-cluster" aria-label="Permalink to &quot;Cannot use the metrics-server securely in a kubeadm cluster&quot;">​</a></h2><p>In a kubeadm cluster, the <a href="https://github.com/kubernetes-sigs/metrics-server" target="_blank" rel="noreferrer">metrics-server</a> can be used insecurely by passing the <code>--kubelet-insecure-tls</code> to it. This is not recommended for production clusters.</p><p>If you want to use TLS between the metrics-server and the kubelet there is a problem, since kubeadm deploys a self-signed serving certificate for the kubelet. This can cause the following errors on the side of the metrics-server:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">x509: certificate signed by unknown authority</span></span>
<span class="line"><span style="color:#e1e4e8;">x509: certificate is valid for IP-foo not IP-bar</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">x509: certificate signed by unknown authority</span></span>
<span class="line"><span style="color:#24292e;">x509: certificate is valid for IP-foo not IP-bar</span></span></code></pre></div><p>See <a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/#kubelet-serving-certs" target="_blank" rel="noreferrer">Enabling signed kubelet serving certificates</a> to understand how to configure the kubelets in a kubeadm cluster to have properly signed serving certificates.</p><p>Also see <a href="https://github.com/kubernetes-sigs/metrics-server/blob/master/FAQ.md#how-to-run-metrics-server-securely" target="_blank" rel="noreferrer">How to run the metrics-server securely</a>.</p>`,101),t=[l];function p(r,c,i,d,u,y){return e(),a("div",null,t)}const b=s(n,[["render",p]]);export{E as __pageData,b as default};
